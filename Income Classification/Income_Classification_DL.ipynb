{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <h1 style=\"text-align:center\"> Drexel University </h1>\n",
    "<h2 style = \"text-align:center\"> College of Computing and Informatics</h2>\n",
    "<h2 style = \"text-align:center\">DSCI 631: Applied Machine Learning</h2>\n",
    "<h3 style = \"text-align:center\">Assignment 2</h3>\n",
    "<h4> </h4>\n",
    "<div style=\"text-align:center; border-style:solid; padding: 10px\">\n",
    "<div style=\"font-weight:bold\">Due Date: Sunday, February 21, 2021</div>\n",
    "This assignment counts for 15% of the final grade\n",
    "</div>\n",
    "\n",
    "<h3 style=\"color:red; font-weight:bold; text-decoration: underline\">DON'T FORGET TO PUT YOUR TEAM NUMBER AND MEMBERS' NAMES BELOW</h3>\n",
    "### TEAM NUMBER: \n",
    "Group 1 <br>\n",
    "### TEAM MEMBERS: \n",
    "Dustin Luchmee, Laura Quinlan, Toby Sheung <br>\n",
    "\n",
    "### A. Assignment Overview\n",
    "This assignment provides the opportunity for you to practice with various skills in feature analysis, feature selection, binary and multi-class classification (imbalance handling) and model tuning.\n",
    "\n",
    "<h4 style=\"color:blue; font-weight:bold\">The goal of this assignment is to provide a realistic setting for a machine learning task. Therefore instructions will not specify the exact steps to carry out. Instead, it is part of the assignment to identify promising features, models and preprocessing methods and apply them as appropriate.</h4>\n",
    "\n",
    "\n",
    "### B. What to Hand In\n",
    "\t\n",
    "Sumbit a completed this Jupyter notebook. \n",
    "\n",
    "### C. How to Hand In\n",
    "\n",
    "Submit your Jupyter notebook file through the course website in the Blackboard Learn system.\n",
    "\n",
    "### D. When to Hand In\n",
    "\n",
    "1. Submit your assignment no later than 11:59 pm in the due date.\n",
    "2. There will be a 10% (absolute value) deduction for each day of lateness, to a maximum of 3 days; assignments will not be accepted beyond that point. Missing work will earn a zero grade.\n",
    "\n",
    "### E. Written Presentation Requirements (if applicable)\n",
    "Images must be clear and legible. Assignments will be judged on the basis of visual appearance, grammatical correctness, and quality of writing, as well as their contents. Please make sure that the text of your assignments is well-structured, using paragraphs, full sentences, and other features of well-written presentation.\n",
    "\n",
    "### F. Academic Honesty\n",
    "\n",
    "Each student is required to submit the Academic Honesty Form at the beginning of the term to cover all the deliverables (for example: assignments, projects, quizzes). Each piece of work must be original. That means, individual quizzes must be done individually without discussing and collaborating with anybody else. Team assignments must be written and programmed by your own team members. No team should copy any piece of work from other teams. The Drexel University Academic Honesty Rules and Procedures (as stated in the student handbook) will be adhered to strictly.  \n",
    "\n",
    "### G. Marking Schemes:\n",
    "\n",
    "Marking assignments will be based on several aspects: presentation, correctness and coding styles. \n",
    "\n",
    "For programming questions, 10% of the mark will be judged on the coding style. \n",
    "\n",
    "The following is a set of guidelines for the coding style in this course:\n",
    "1. Write a good comment.\n",
    "2. Use appropriate indentations to indicate control flows and blocks of code. \n",
    "3. When breaking up a long line, break it before an operator, not after. \n",
    "\n",
    "### H. Answer the following questions: \n",
    "**Your answer should be combined with code and brief text answer.** Please ensure that your Jupyter notebook does not have too much spurious output. If you like, you can share your notebook in progress with me on Kaggle: leiwangv (lw474@drexel.edu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for Binary Classification in this assignment:\n",
    "* URL: https://www.kaggle.com/lodetomasi1995/income-classification\n",
    "* On Kaggel Notebook, you can add the data set by searching the above URL\n",
    "* Column “income” is the target label to classify.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Kaggle Notebook, after adding the data, you can import the data as Pandas DataFrame as follows\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "df = pd.read_csv(\"data/income_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1-1:\n",
    "Examine the features of the data. Identify which feature is continuous and which feature is categorical. Make some analyses and statistics, then use the results to discuss your selected predictors. You may also derive new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', ' workclass', ' fnlwgt', ' education', ' education-num',\n",
       "       ' marital-status', ' occupation', ' relationship', ' race', ' sex',\n",
       "       ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country',\n",
       "       ' income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous:** age, fnlwgt, education-num, capital-gain, capital-loss, hours-per-week <br>\n",
    "**Categorical:** workclass, education, martial-status, occupation, relationship, race, sex, native-country, income (target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Plotting the numerical variables\n",
    "df.hist(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "The scaling of the continuous variables need to be scaled to similar numbers. There are some right skewness with features such as age, fnlwgt and capital-gain. Perhaps a log transformation will be used to create a normal distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the categorical variables\n",
    "df[' workclass'].value_counts().plot(kind = 'bar', figsize=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "Most of the workclass instances are private. The feature could possibly be omitted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' education'].value_counts().plot(kind = 'bar', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** <br>\n",
    "Both education and education-num seem to be similar features about the same concept. The only difference is that one is numerical and another is categorical and more specific about the education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' marital-status'].value_counts().plot(kind = 'bar', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' occupation'].value_counts().plot(kind = 'bar', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' relationship'].value_counts().plot(kind = 'bar', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' race'].value_counts().plot(kind = 'bar', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " White                 27816\n",
       " Black                  3124\n",
       " Asian-Pac-Islander     1039\n",
       " Amer-Indian-Eskimo      311\n",
       " Other                   271\n",
       "Name:  race, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' sex'].value_counts().plot(kind = 'bar', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Male      21790\n",
       " Female    10771\n",
       "Name:  sex, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barplot of sex and income level\n",
    "sns.countplot(data = df, x = ' income', hue = ' sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examination of how sex affects the other numerical features\n",
    "sns.pairplot(data = df, hue = ' sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** <br>\n",
    "From the above plot analysis, it is highly likely that sex would play a large part in whether or not someone makes more than 50K. Although there are more male data instances, there are 10,000 instances that are female.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' native-country'].value_counts().plot(kind = 'bar', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "When examining the categorical features, the most unlikely useful variable to help create a good model is the native-country feature. Most of instances are from the United-States. Another feature that may not be too helpful is the race variable. Much of the data are those that are white. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       " workclass         1836\n",
       " fnlwgt               0\n",
       " education            0\n",
       " education-num        0\n",
       " marital-status       0\n",
       " occupation        1843\n",
       " relationship         0\n",
       " race                 0\n",
       " sex                  0\n",
       " capital-gain         0\n",
       " capital-loss         0\n",
       " hours-per-week       0\n",
       " native-country     583\n",
       " income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examination of missing values\n",
    "df.isin([' ?']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "When using the info() for this dataset, I was surprised to see that there were no missing values. But a closer examination of the values in the occupation barplot shows that ? is used as a placeholder. Both workclass and occupation have a close number of missing values and the variables are similar to each other. The next step is to examine how many missing value indexes within workclass and occupation are the same instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Captures index of workclass index with missing values\n",
    "work_array = df[' workclass'].isin([' ?'])\n",
    "work_miss = np.where(work_array)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Captures index of occupation index with missing values\n",
    "occup_array = df[' occupation'].isin([' ?'])\n",
    "occup_miss = np.where(occup_array)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   27    61    69 ... 32539 32541 32542]\n",
      "[   27    61    69 ... 32539 32541 32542]\n"
     ]
    }
   ],
   "source": [
    "#Quick examination of the missing index of workclass and occupation\n",
    "print(work_miss)\n",
    "print(occup_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1836"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print number of matching missing indexes for workclass and occupation\n",
    "len(set(work_miss) & set(occup_miss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "The above analysis shows that the all of the workclass missing instances are the same in the occupation feature. There are 1836 missing instances that have both missing workclass and occupation information. Perhaps when hot encoding, creating a new category for the missing value would be a good choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>income_ &lt;=50K</th>\n",
       "      <th>income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   fnlwgt   education-num   capital-gain   capital-loss  \\\n",
       "0   39    77516              13           2174              0   \n",
       "1   50    83311              13              0              0   \n",
       "2   38   215646               9              0              0   \n",
       "3   53   234721               7              0              0   \n",
       "4   28   338409              13              0              0   \n",
       "\n",
       "    hours-per-week   workclass_ ?   workclass_ Federal-gov  \\\n",
       "0               40              0                        0   \n",
       "1               13              0                        0   \n",
       "2               40              0                        0   \n",
       "3               40              0                        0   \n",
       "4               40              0                        0   \n",
       "\n",
       "    workclass_ Local-gov   workclass_ Never-worked  ...   relationship_ Wife  \\\n",
       "0                      0                         0  ...                    0   \n",
       "1                      0                         0  ...                    0   \n",
       "2                      0                         0  ...                    0   \n",
       "3                      0                         0  ...                    0   \n",
       "4                      0                         0  ...                    1   \n",
       "\n",
       "    race_ Amer-Indian-Eskimo   race_ Asian-Pac-Islander   race_ Black  \\\n",
       "0                          0                          0             0   \n",
       "1                          0                          0             0   \n",
       "2                          0                          0             0   \n",
       "3                          0                          0             1   \n",
       "4                          0                          0             1   \n",
       "\n",
       "    race_ Other   race_ White   sex_ Female   sex_ Male   income_ <=50K  \\\n",
       "0             0             1             0           1               1   \n",
       "1             0             1             0           1               1   \n",
       "2             0             1             0           1               1   \n",
       "3             0             0             0           1               1   \n",
       "4             0             0             1           0               1   \n",
       "\n",
       "    income_ >50K  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copying the dataset to use the dummy encoder to test out feature selection model\n",
    "copy_df = df.copy()\n",
    "copy_df = copy_df.drop([' native-country'], axis = 1)\n",
    "copy_df_dum = pd.get_dummies(data = copy_df)\n",
    "copy_df_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_dum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " income_ >50K                          1.000000\n",
       " marital-status_ Married-civ-spouse    0.444696\n",
       " relationship_ Husband                 0.401035\n",
       " education-num                         0.335154\n",
       "age                                    0.234037\n",
       " hours-per-week                        0.229689\n",
       " capital-gain                          0.223329\n",
       " sex_ Male                             0.215980\n",
       " occupation_ Exec-managerial           0.214861\n",
       " occupation_ Prof-specialty            0.185866\n",
       "Name:  income_ >50K, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = copy_df_dum.corr()\n",
    "corr[' income_ >50K'].sort_values(ascending = False).head(10)\n",
    "#Wonder if I can average the same categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " income_ <=50K                    1.000000\n",
       " marital-status_ Never-married    0.318440\n",
       " relationship_ Own-child          0.228532\n",
       " sex_ Female                      0.215980\n",
       " relationship_ Not-in-family      0.188497\n",
       " occupation_ Other-service        0.156348\n",
       " relationship_ Unmarried          0.142857\n",
       " education_ HS-grad               0.131189\n",
       " marital-status_ Divorced         0.126995\n",
       " occupation_ Adm-clerical         0.089986\n",
       "Name:  income_ <=50K, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr[' income_ <=50K'].sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>marital-status_ Married-civ-spouse</th>\n",
       "      <th>income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   fnlwgt   education-num   capital-gain   capital-loss  \\\n",
       "0       39    77516              13           2174              0   \n",
       "1       50    83311              13              0              0   \n",
       "2       38   215646               9              0              0   \n",
       "3       53   234721               7              0              0   \n",
       "4       28   338409              13              0              0   \n",
       "...    ...      ...             ...            ...            ...   \n",
       "32556   27   257302              12              0              0   \n",
       "32557   40   154374               9              0              0   \n",
       "32558   58   151910               9              0              0   \n",
       "32559   22   201490               9              0              0   \n",
       "32560   52   287927               9          15024              0   \n",
       "\n",
       "        hours-per-week   marital-status_ Married-civ-spouse   income_ >50K  \n",
       "0                   40                                    0              0  \n",
       "1                   13                                    1              0  \n",
       "2                   40                                    0              0  \n",
       "3                   40                                    1              0  \n",
       "4                   40                                    1              0  \n",
       "...                ...                                  ...            ...  \n",
       "32556               38                                    1              0  \n",
       "32557               40                                    1              1  \n",
       "32558               40                                    0              0  \n",
       "32559               20                                    0              0  \n",
       "32560               40                                    1              1  \n",
       "\n",
       "[32561 rows x 8 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marital_data = copy_df_dum.loc[:,['age', ' fnlwgt', ' education-num', ' capital-gain', ' capital-loss',\n",
    "       ' hours-per-week', ' marital-status_ Married-civ-spouse', ' income_ >50K']]\n",
    "marital_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'marital_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f23cc0de8c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmarital_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarital_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#sns.heatmap(marital_corr, cmap = 'YlGnBu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'marital_data' is not defined"
     ]
    }
   ],
   "source": [
    "marital_corr = marital_data.corr()\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(marital_corr, cmap = 'YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "From the above analysis, some important features for the prediction model is sex, martial_status(Married-civ-spouse) and education-num.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1-2:\n",
    "Check if the target label is balanced or not, what is your strategy if imbalanced? apply your strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " <=50K    24720\n",
       " >50K      7841\n",
       "Name:  income, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' income'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "The target label is imbalanced and the strategy that will be used on this is the SMOTE technique. SMOTE allows the creation of new instances that are similar to the original data. Unlike upsampling, there will not be repeated instances. But in order to use this technique, the data will have to be split, cleaned and hot encoded before the use of SMOTE to prevent data leakage. This strategy will be applied within the pipeline in the next question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1-3: \n",
    "Split the data into train and test data, then build Pipeline, apply transformer as needed, train the following 4 algorithms (Logistic Regression, Support Vector Machines, Naïve Bayes and K-Nearest Neighbors) with hyperparameter tuning, to classify the \"income\". Compare the performance of different algorithms on Test set. Discuss your results and findings.\n",
    "\n",
    "For Naïve Bayes, which algortihm you adopted here, why you choose this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Set labels\n",
    "train_labels = train_set[\" income\"] \n",
    "test_labels = test_set[\" income\"]\n",
    "\n",
    "#Drop target from training and testing set\n",
    "true_train_set = train_set.drop(\" income\", axis = 1)\n",
    "true_test_set = test_set.drop(\" income\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>33</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>198183</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19777</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>86459</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10781</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>203039</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32240</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>180190</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>279872</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass   fnlwgt      education   education-num  \\\n",
       "5514    33          Local-gov   198183      Bachelors              13   \n",
       "19777   36            Private    86459      Assoc-voc              11   \n",
       "10781   58   Self-emp-not-inc   203039            9th               5   \n",
       "32240   21            Private   180190      Assoc-voc              11   \n",
       "9876    27            Private   279872   Some-college              10   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "5514         Never-married    Prof-specialty   Not-in-family   White   Female   \n",
       "19777   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "10781            Separated      Craft-repair   Not-in-family   White     Male   \n",
       "32240   Married-civ-spouse   Farming-fishing         Husband   White     Male   \n",
       "9876              Divorced     Other-service   Not-in-family   White     Male   \n",
       "\n",
       "        capital-gain   capital-loss   hours-per-week  native-country  \n",
       "5514               0              0               50   United-States  \n",
       "19777              0           1887               50   United-States  \n",
       "10781              0              0               40   United-States  \n",
       "32240              0              0               46   United-States  \n",
       "9876               0              0               40   United-States  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', ' workclass', ' fnlwgt', ' education', ' education-num',\n",
       "       ' marital-status', ' occupation', ' relationship', ' race', ' sex',\n",
       "       ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since native-country does not tell much information, it is dropped\n",
    "\n",
    "true_train_set = true_train_set.drop([\" native-country\", \" workclass\", \" race\", \" fnlwgt\", \" capital-loss\"], axis = 1)\n",
    "true_test_set = true_test_set.drop([\" native-country\", \" workclass\", \" race\", \" fnlwgt\", \" capital-loss\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>33</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19777</th>\n",
       "      <td>36</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10781</th>\n",
       "      <td>58</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32240</th>\n",
       "      <td>21</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>27</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      education   education-num       marital-status  \\\n",
       "5514    33      Bachelors              13        Never-married   \n",
       "19777   36      Assoc-voc              11   Married-civ-spouse   \n",
       "10781   58            9th               5            Separated   \n",
       "32240   21      Assoc-voc              11   Married-civ-spouse   \n",
       "9876    27   Some-college              10             Divorced   \n",
       "\n",
       "             occupation    relationship      sex   capital-gain  \\\n",
       "5514     Prof-specialty   Not-in-family   Female              0   \n",
       "19777   Exec-managerial         Husband     Male              0   \n",
       "10781      Craft-repair   Not-in-family     Male              0   \n",
       "32240   Farming-fishing         Husband     Male              0   \n",
       "9876      Other-service   Not-in-family     Male              0   \n",
       "\n",
       "        hours-per-week  \n",
       "5514                50  \n",
       "19777               50  \n",
       "10781               40  \n",
       "32240               46  \n",
       "9876                40  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate categorical and numerical variables for pipeline\n",
    "\n",
    "cate_attr = [\" marital-status\", \" education\", \" relationship\", \" occupation\", \" sex\"]\n",
    "num_attr = [\"age\", \" education-num\", \" hours-per-week\", \" capital-gain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining categorical and numerical pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "combine_pipeline = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_attr),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown = \"ignore\"), cate_attr),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and Transform Train\n",
    "trans_train = combine_pipeline.fit_transform(true_train_set)\n",
    "\n",
    "\n",
    "#Transform Test\n",
    "trans_test = combine_pipeline.transform(true_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SMOTE algorithm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state = 42)\n",
    "\n",
    "#resample training set\n",
    "x_smote_train, x_smote_labels = smote.fit_resample(trans_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without specific hyperparameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Logistic Regression algorithm\n",
    "log_reg = LogisticRegression(random_state = 42, solver='lbfgs', max_iter = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=400, random_state=42)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8053124520190389 0.8453214513049013 0.5643858903527412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.94      0.79      0.86      4942\n",
      "        >50K       0.56      0.85      0.68      1571\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.82      0.77      6513\n",
      "weighted avg       0.85      0.81      0.82      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logisitic Regression Model Score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "#Predict labels\n",
    "pred_log_reg = log_reg.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "log_acc = accuracy_score(pred_log_reg, test_labels)\n",
    "#precision score\n",
    "log_prec = precision_score(pred_log_reg, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "log_recall = recall_score(pred_log_reg, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(log_acc, log_prec, log_recall)\n",
    "print(classification_report(test_labels, pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state = 42)\n",
    "\n",
    "#Hyperparameter choices\n",
    "param_grid = [\n",
    "    {\"penalty\" : [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "    \"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "     \"max_iter\" : [300, 400, 500, 1000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use of GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyper_log = GridSearchCV(log_reg, param_grid = param_grid, cv = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_log = hyper_log.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find best hyperparameters to use with log regression\n",
    "\n",
    "find_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine accuracy for training set and training labels\n",
    "find_log.score(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use on testing\n",
    "\n",
    "log_reg2 = LogisticRegression(random_state = 42, solver = \"liblinear\", penalty = \"l1\", max_iter = 300)\n",
    "log_reg2.fit(x_smote_train, x_smote_labels)\n",
    "\n",
    "#Predict labels\n",
    "pred_log_reg = log_reg2.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "hyper_log_acc = accuracy_score(pred_log_reg, test_labels)\n",
    "#precision score\n",
    "hyper_log_prec = precision_score(pred_log_reg, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "hyper_log_recall = recall_score(pred_log_reg, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(hyper_log_acc, hyper_log_prec, hyper_log_recall)\n",
    "print(classification_report(test_labels, pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "Even with GridSearchCV and hyperparamter tuning, the results of the accuracy, precision and recall is the same as the first logistic regression model without any specific reasoning with its hyperparameters. Both the accuracy and precision score is not bad, only the recall is slightly lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without specific hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, loss='hinge')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#SVM Linear Algorithm\n",
    "svm = LinearSVC(C = 1, loss = \"hinge\")\n",
    "svm.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7910333179794258 0.852959898154042 0.5425101214574899\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "svm_acc = accuracy_score(pred_svm, test_labels)\n",
    "#precision score\n",
    "svm_prec = precision_score(pred_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "svm_recall = recall_score(pred_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(svm_acc, svm_prec, svm_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()\n",
    "\n",
    "#Hyperparameter choices\n",
    "param_grid = [\n",
    "    {\"penalty\" : [\"l1\", \"l2\"],\n",
    "    \"loss\" : [\"hinge\", \"squared_hinge\"],\n",
    "     \"C\" : [1.0, 2.0, 3.0, 0.5]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create GridSearch for SVM\n",
    "hyper_lsvm = GridSearchCV(svm, param_grid = param_grid, cv = 3, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x7fa8846fe6a0 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 347, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 780, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n",
      "The exit codes of the workers are {SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-359aef3ccf5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_l_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper_lsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_smote_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_smote_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \"\"\"\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0m\u001b[1;32m    178\u001b[0m                 fn, *args, **kwargs)\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6)}"
     ]
    }
   ],
   "source": [
    "find_l_svm = hyper_lsvm.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_l_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82146829810901"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training score\n",
    "find_l_svm.score(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7994779671426377 0.8491406747294716 0.5551394090719933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.94      0.78      0.86      4942\n",
      "        >50K       0.56      0.85      0.67      1571\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.82      0.76      6513\n",
      "weighted avg       0.85      0.80      0.81      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use on testing\n",
    "\n",
    "svm_2 = LinearSVC(C = 0.5)\n",
    "svm_2.fit(x_smote_train, x_smote_labels)\n",
    "\n",
    "#Predict labels\n",
    "pred_svm = svm_2.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "hyper_svm_acc = accuracy_score(pred_svm, test_labels)\n",
    "#precision score\n",
    "hyper_svm_prec = precision_score(pred_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "hyper_svm_recall = recall_score(pred_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(hyper_svm_acc, hyper_svm_prec, hyper_svm_recall)\n",
    "print(classification_report(test_labels, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, coef0=1, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Poly SVM\n",
    "p_svm = SVC(kernel = \"poly\", degree = 2, coef0 = 1, C = 5)\n",
    "p_svm.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8062336864732075 0.8478676002546149 0.5656050955414013\n"
     ]
    }
   ],
   "source": [
    "pred_p_svm = p_svm.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "p_svm_acc = accuracy_score(pred_p_svm, test_labels)\n",
    "#precision score\n",
    "p_svm_prec = precision_score(pred_p_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "p_svm_recall = recall_score(pred_p_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(p_svm_acc, p_svm_prec, p_svm_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, coef0=2, kernel='poly')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Poly SVM\n",
    "p_svm = SVC(kernel = \"poly\", degree = 3, coef0 = 2, C = 5)\n",
    "p_svm.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8080761553815446 0.8427753023551878 0.568972926514826\n"
     ]
    }
   ],
   "source": [
    "pred_p_svm = p_svm.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "p_svm_acc2 = accuracy_score(pred_p_svm, test_labels)\n",
    "#precision score\n",
    "p_svm_prec2 = precision_score(pred_p_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "p_svm_recall2 = recall_score(pred_p_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(p_svm_acc2, p_svm_prec2, p_svm_recall2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.001, gamma=5)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gaussian RBF Kernel\n",
    "g_svm = SVC(kernel = \"rbf\", gamma = 5, C = 0.001)\n",
    "g_svm.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7735298633502227 0.12348822406110757 0.6643835616438356\n"
     ]
    }
   ],
   "source": [
    "g_pred_svm = g_svm.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "g_svm_acc = accuracy_score(g_pred_svm, test_labels)\n",
    "#precision score\n",
    "g_svm_prec = precision_score(g_pred_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "g_svm_recall = recall_score(g_pred_svm, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(g_svm_acc, g_svm_prec, g_svm_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7454322124980808 0.8357733927434755 0.48396608920014744\n"
     ]
    }
   ],
   "source": [
    "pred_bnb = bnb.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "bnb_acc = accuracy_score(pred_bnb, test_labels)\n",
    "#precision score\n",
    "bnb_prec = precision_score(pred_bnb, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "bnb_recall = recall_score(pred_bnb, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(bnb_acc, bnb_prec, bnb_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=2.0)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB(alpha = 2.0)\n",
    "bnb.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7454322124980808 0.8357733927434755 0.48396608920014744\n"
     ]
    }
   ],
   "source": [
    "pred_bnb = bnb.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "bnb_acc2 = accuracy_score(pred_bnb, test_labels)\n",
    "#precision score\n",
    "bnb_prec2 = precision_score(pred_bnb, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "bnb_recall2 = recall_score(pred_bnb, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(bnb_acc2, bnb_prec2, bnb_recall2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "The Bernoulli Naive Bayes model was chosen due to its usefulness in binary algorithms. The Bernoulli distribution assumes that there are only two values (0 or 1). It expects binary feature vectors and our dataset uses the one-hot encoding to make the features either 0 or 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7921080915092891 0.7097390197326544 0.553899652260308\n"
     ]
    }
   ],
   "source": [
    "pred_knn = knn.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "knn_acc = accuracy_score(pred_knn, test_labels)\n",
    "#precision score\n",
    "knn_prec = precision_score(pred_knn, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "knn_recall = recall_score(pred_knn, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(knn_acc, knn_prec, knn_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 2)\n",
    "knn.fit(x_smote_train, x_smote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8105327805926609 0.5334182049649905 0.6258401792382375\n"
     ]
    }
   ],
   "source": [
    "pred_knn = knn.predict(trans_test)\n",
    "\n",
    "#accuracy score\n",
    "knn_acc2 = accuracy_score(pred_knn, test_labels)\n",
    "#precision score\n",
    "knn_prec2 = precision_score(pred_knn, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "#recall_score\n",
    "knn_recall2 = recall_score(pred_knn, test_labels, average = 'binary', pos_label = \" >50K\")\n",
    "\n",
    "print(knn_acc2, knn_prec2, knn_recall2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.805312</td>\n",
       "      <td>0.845321</td>\n",
       "      <td>0.564386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.799478</td>\n",
       "      <td>0.849141</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM Poly</td>\n",
       "      <td>0.808076</td>\n",
       "      <td>0.842775</td>\n",
       "      <td>0.568973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM Gaussian</td>\n",
       "      <td>0.773530</td>\n",
       "      <td>0.123488</td>\n",
       "      <td>0.664384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.745432</td>\n",
       "      <td>0.835773</td>\n",
       "      <td>0.483966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>0.810533</td>\n",
       "      <td>0.533418</td>\n",
       "      <td>0.625840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall\n",
       "0  Logistic Regression  0.805312   0.845321  0.564386\n",
       "1                  SVM  0.799478   0.849141  0.555139\n",
       "2             SVM Poly  0.808076   0.842775  0.568973\n",
       "3         SVM Gaussian  0.773530   0.123488  0.664384\n",
       "4          Naive Bayes  0.745432   0.835773  0.483966\n",
       "5   K-Nearest Neighbor  0.810533   0.533418  0.625840"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creation of metrics dataframe\n",
    "import pandas as pd\n",
    "\n",
    "model_metrics = pd.DataFrame([[\"Logistic Regression\", log_acc, log_prec, log_recall], \n",
    "                              [\"SVM\", hyper_svm_acc, hyper_svm_prec, hyper_svm_recall],\n",
    "                              [\"SVM Poly\", p_svm_acc2, p_svm_prec2, p_svm_recall2],\n",
    "                              [\"SVM Gaussian\", g_svm_acc, g_svm_prec, g_svm_recall],\n",
    "                              [\"Naive Bayes\", bnb_acc, bnb_prec, bnb_recall],\n",
    "                              [\"K-Nearest Neighbor\", knn_acc2, knn_prec2, knn_recall2]],\n",
    "                             columns = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\"])\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "K-Nearest Neighbor has the highest accuracy among the model but lower precision. The logistic regression and the poly SVM also did a good job in identifing the target classes and having the highest scores in precision. All of the models have a lower score in recall and have a harder time in the sensitivity of identifying true positives. In this dataset, I believe that having a higher score in accuracy and precision is fine with solving the task of classifing whether or not a person makes more than 50K. \n",
    "\n",
    "The lowest model is the SVM Gaussian, especially with such a low precision score. The better support vector machine model is the poly svm or linear svm in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1-4:\n",
    "Identify features that are important for your best model. Which features are most influential? Which features could be removed without decrease in performance? Does removing irrelevant features make your model better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "Most influential features: martial-status, education-num, relationship  <br>\n",
    "Features that could be removed without decrease in performance were fnlwgt, capital-loss, race, native-country <br>\n",
    "Features removed that increased performance: workclass <br>\n",
    "\n",
    "The other features such as sex, age, capital-gain, hours-per-week, education, occupation helped a little bit with the model's numbers. When several irrelevant features are removed, the models are run a little faster. Only when removing workclass did the performance of the model increase for the logisitic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for Multiple-class Classification in this assignment:\n",
    "* URL: https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones\n",
    "* On Kaggel Notebook, you can add the data set by searching the above URL\n",
    "* Column “Activity” is the target label to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Kaggle Notebook, after adding the data, you can import the data as Pandas DataFrame as follows\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 563)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2-1:\n",
    "Create plots to visualize the distribution of the label \"Activity\". If the distribution of each class is balanced?\n",
    "If imbalanced, what strategies would you adopt and why? Apply your strategy on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAYING                1407\n",
       "STANDING              1374\n",
       "SITTING               1286\n",
       "WALKING               1226\n",
       "WALKING_UPSTAIRS      1073\n",
       "WALKING_DOWNSTAIRS     986\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Activity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Activity\"].value_counts().plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "The distribution of the target label is not too imbalanced. But the category \"Walking_Downstairs\" has 400 less instances than \"Laying\" the highest instance. Perhaps using a imbalancing strategy would be good to allow all of the categories have an equal footing in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Activity'], dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine that only the target variable is not numerical\n",
    "df_train.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Set\n",
    "x_train = df_train.drop(\"Activity\", axis = 1)\n",
    "\n",
    "#Train labels\n",
    "y_train = df_train[\"Activity\"]\n",
    "\n",
    "#Test Set\n",
    "x_test = df_test.drop(\"Activity\", axis = 1)\n",
    "\n",
    "#Test labels\n",
    "y_test = df_test[\"Activity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Values for Target Label\n",
    "\n",
    "Laying = 0 <br>\n",
    "Standing = 1 <br>\n",
    "Sitting = 2 <br>\n",
    "Walking = 3 <br>\n",
    "Walking_Upstairs = 4 <br>\n",
    "Walking_Downstairs = 5 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace categorical target to numerical\n",
    "\n",
    "cate_to_num = {\"LAYING\": 0, \"STANDING\": 1, \"SITTING\": 2, \"WALKING\": 3, \"WALKING_UPSTAIRS\": 4, \"WALKING_DOWNSTAIRS\": 5}\n",
    "#Replace train labels\n",
    "num_y_train = y_train.replace(cate_to_num)\n",
    "\n",
    "#Replace test labels\n",
    "num_y_test = y_test.replace(cate_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 562)\n",
      "(8442, 562)\n",
      "(8442,)\n"
     ]
    }
   ],
   "source": [
    "#Upsampling data\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "up = RandomOverSampler()\n",
    "x_train_up, y_train_up = up.fit_sample(x_train, num_y_train)\n",
    "print(x_train.shape)\n",
    "print(x_train_up.shape)\n",
    "print(y_train_up.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "The imbalancing strategy used is the Upsampling technique. Due to the overall target labels instances being so low, I chose not to downsample. SMOTE was not used because its use of the euclidean distance to create new instances. The target labels are not ordinal in any way that would allow the use of distances to create useful instances. Upsampling was used because the number of instances created would not be so high and the affect on the model with repeated instances would perhaps be minimal.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2-2:\n",
    "Evaluate the performance of multi-class classification with 3 self-selected classification algorithm with hyperparameter tuning. \n",
    "\n",
    "Of the algorithms you selected, can each of them capable of handling multiple classes natively? Then what strategy/strategies can be applied to perform multiclass classification for those algorithms in order to perform multi-class classification? \n",
    "\n",
    "Compare the performance of different algorithms on Test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "d_tree = DecisionTreeClassifier(max_depth = 2)\n",
    "d_tree_model = d_tree.fit(x_train_up, y_train_up)\n",
    "d_tree_pred = d_tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[537,   0,   0,   0,   0,   0],\n",
       "       [  0, 532,   0,   0,   0,   0],\n",
       "       [  0, 491,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 496,   0,   0],\n",
       "       [  0,   0,   0, 471,   0,   0],\n",
       "       [  0,   0,   0, 420,   0,   0]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(num_y_test, d_tree_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeClassifier(max_depth = 3, criterion = \"entropy\")\n",
    "d_tree_model = d_tree.fit(x_train_up, y_train_up)\n",
    "d_tree_pred = d_tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[537,   0,   0,   0,   0,   0],\n",
       "       [  0, 425, 107,   0,   0,   0],\n",
       "       [  0,  91, 400,   0,   0,   0],\n",
       "       [  0,   0,   0, 437,  48,  11],\n",
       "       [  0,   0,   0, 129, 336,   6],\n",
       "       [  0,   0,   0, 107,  52, 261]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(num_y_test, d_tree_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** <br>\n",
    "The first decision tree did not do well in identifying the 2 (Sitting), 4 (Walking_Upstairs) or 5 (Walking_Downstairs) class. The second tree used the entropy criterion and had better classification of each class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(decision_function_shape='ovo')\n",
    "svm_model = svm.fit(x_train_up, y_train_up)\n",
    "svm_pred = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[537,   0,   0,   0,   0,   0],\n",
       "       [  0, 485,  47,   0,   0,   0],\n",
       "       [  0,  59, 430,   0,   2,   0],\n",
       "       [  0,   0,   0, 494,   0,   2],\n",
       "       [  0,   0,   0,  19, 450,   2],\n",
       "       [  0,   0,   0,  27,  26, 367]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(num_y_test, svm_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(decision_function_shape='ovo', kernel = \"poly\", C = 2.0)\n",
    "svm_model = svm.fit(x_train_up, y_train_up)\n",
    "svm_pred = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[537,   0,   0,   0,   0,   0],\n",
       "       [  0, 499,  33,   0,   0,   0],\n",
       "       [  0,  55, 435,   0,   1,   0],\n",
       "       [  0,   0,   0, 490,   0,   6],\n",
       "       [  0,   0,   0,  24, 443,   4],\n",
       "       [  0,   0,   0,  32,  24, 364]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(num_y_test, svm_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "Even with the hyperparameter changes, the SVM model has the best score among the other classifiers. The linear svm vs the poly svm has no considerable differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn_model = knn.fit(x_train_up, y_train_up)\n",
    "knn_pred = knn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[507,   6,  23,   0,   1,   0],\n",
       "       [  0, 458,  73,   1,   0,   0],\n",
       "       [  0, 149, 340,   0,   2,   0],\n",
       "       [  0,   0,   0, 416,  32,  48],\n",
       "       [  0,   0,   0,  98, 342,  31],\n",
       "       [  0,   0,   0,  65,  34, 321]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(num_y_test, knn_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_model = knn.fit(x_train_up, y_train_up)\n",
    "knn_pred = knn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[510,   8,  19,   0,   0,   0],\n",
       "       [  0, 450,  81,   1,   0,   0],\n",
       "       [  0, 154, 335,   0,   2,   0],\n",
       "       [  0,   0,   0, 413,  30,  53],\n",
       "       [  0,   0,   0,  99, 332,  40],\n",
       "       [  0,   0,   0,  59,  34, 327]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(num_y_test, knn_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "The K-Nearest Neighbor models are quite similar to each other. They both do relatively well compared to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb_model = gnb.fit(x_train_up, y_train_up)\n",
    "gnb_pred = gnb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[343,   0, 191,   0,   3,   0],\n",
       "       [  7, 444,  66,   0,  15,   0],\n",
       "       [  5, 103, 376,   0,   7,   0],\n",
       "       [  0,   0,   0, 418,  35,  43],\n",
       "       [  0,   0,   0,   9, 450,  12],\n",
       "       [  0,   0,   0,  79,  83, 258]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(num_y_test, gnb_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** <br>\n",
    "If Logistic Regression was chosen as one of the classification algorithm for this data, then we would have to use the OneVSRestClassifer or OneVsOneClassifier to handle multiple target classes. But in this case, the algorithms except SVM were capable of handling multiple classes. SVM needed to use the OneVSRestClassifier or OneVSOneClassifer. \n",
    "\n",
    "Overall, the SVM model did the best at separating the 6 classes and identifing the correct targets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
